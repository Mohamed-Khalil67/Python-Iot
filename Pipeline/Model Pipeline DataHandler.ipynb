{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importer vos librairies\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import datetime as DT\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "    def __init__(self) :\n",
    "        self.dataprice = None\n",
    "        self.datalisting = None\n",
    "        self.merge = None\n",
    "    def get_data(self):\n",
    "        print(\"_ _ Fetch Data From bucket _ _\")\n",
    "        self.dataprice=pd.read_csv(\"price_availability.csv\",sep=';')  # What is csv : comma separateur virgule\n",
    "        self.datalisting=pd.read_csv(\"listings_final.csv\",sep=';')\n",
    "        return \"_ _  data loaded _ _\\nFiles : \\n - listing {} \\n - prices {} \".format(self.datalisting.shape,self.dataprice.shape)\n",
    "    def group_data(self):\n",
    "        data = self.dataprice.groupby('listing_id')['local_price'].mean()\n",
    "        self.merge = pd.merge(data, self.datalisting, on='listing_id')\n",
    "        print(\" - - - data merged - - - \")\n",
    "    def get_process_data(self):\n",
    "        self.get_data()\n",
    "        self.group_data()\n",
    "        print(self.merge)\n",
    "        print(\"-- End of DataHandling --\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DataHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_ _ Fetch Data From bucket _ _\n",
      " - - - data merged - - - \n",
      "     listing_id  local_price  Unnamed: 0  \\\n",
      "0         56093   170.000000          12   \n",
      "1         57207    49.952756          13   \n",
      "2        114543   107.374026          19   \n",
      "3        149534   169.000000           9   \n",
      "4        164255    75.876209          28   \n",
      "..          ...          ...         ...   \n",
      "994    28684174   725.175781         662   \n",
      "995    28709644   475.000000         745   \n",
      "996    28751412   117.000000          88   \n",
      "997    28774896   156.397468         159   \n",
      "998    28792796    49.184211         998   \n",
      "\n",
      "                                                  name          type   city  \\\n",
      "0                          Beau duplex dans le Marais    entire_home  Paris   \n",
      "1                             Belle Chambre pour court  private_room  Paris   \n",
      "2                    Charming 1bdr 55m² - Eiffel Tower   entire_home  Paris   \n",
      "3                   GREAT WARM FULL APT LE HAUT MARAIS   entire_home  Paris   \n",
      "4                   Perfect place in Le Marais - Paris   entire_home  Paris   \n",
      "..                                                 ...           ...    ...   \n",
      "994  Chambre familiale vue jardin avec petit-déjeun...  private_room  Paris   \n",
      "995                 LORD BYRON-SPACE& STYLE IN 8TH EME   entire_home  Paris   \n",
      "996                         Malesherbes Monceau Monsen   entire_home  Paris   \n",
      "997      5 min to invalides and 10 min to eiffel tower   entire_home  Paris   \n",
      "998                  Appartement 3 chambres madeleine.   entire_home  Paris   \n",
      "\n",
      "                    neighborhood   latitude  longitude  person_capacity  beds  \\\n",
      "0              3e arrondissement  48.867284   2.358431                4     2   \n",
      "1                      Vaugirard  48.846184   2.304455                2     1   \n",
      "2                            NaN  48.849530   2.290219                2     1   \n",
      "3                            NaN  48.866360   2.361844                4     2   \n",
      "4              3e arrondissement  48.861398   2.364299                4     2   \n",
      "..                           ...        ...        ...              ...   ...   \n",
      "994                       Ternes  48.879223   2.292382                5     0   \n",
      "995               Champs-Elysées  48.872202   2.298349                4     2   \n",
      "996                      Monceau  48.880923   2.314568                2     1   \n",
      "997  Invalides - Ecole Militaire  48.852915   2.314519                2     1   \n",
      "998          Madeleine - Vendôme  48.870109   2.321475                6     4   \n",
      "\n",
      "     bedrooms  bathrooms  is_rebookable  is_new_listing  is_fully_refundable  \\\n",
      "0           1        1.0          False           False                 True   \n",
      "1           1        1.0          False           False                 True   \n",
      "2           1        1.0          False           False                 True   \n",
      "3           1        1.0          False           False                 True   \n",
      "4           1        1.0          False           False                 True   \n",
      "..        ...        ...            ...             ...                  ...   \n",
      "994         1        1.0          False            True                 True   \n",
      "995         1        1.0          False            True                 True   \n",
      "996         0        1.0          False            True                 True   \n",
      "997         1        1.0          False            True                 True   \n",
      "998         2        1.5          False            True                 True   \n",
      "\n",
      "     is_host_highly_rated  is_business_travel_ready  pricing_weekly_factor  \\\n",
      "0                    True                     False                   0.88   \n",
      "1                   False                     False                   0.87   \n",
      "2                    True                     False                   0.90   \n",
      "3                    True                     False                   1.00   \n",
      "4                   False                     False                   1.00   \n",
      "..                    ...                       ...                    ...   \n",
      "994                 False                     False                   1.00   \n",
      "995                 False                     False                   1.00   \n",
      "996                 False                     False                   1.00   \n",
      "997                 False                     False                   1.00   \n",
      "998                 False                     False                   1.00   \n",
      "\n",
      "     pricing_monthly_factor  \n",
      "0                       1.0  \n",
      "1                       1.0  \n",
      "2                       0.9  \n",
      "3                       0.4  \n",
      "4                       1.0  \n",
      "..                      ...  \n",
      "994                     1.0  \n",
      "995                     1.0  \n",
      "996                     1.0  \n",
      "997                     1.0  \n",
      "998                     1.0  \n",
      "\n",
      "[999 rows x 20 columns]\n",
      "_ _ data processed _ _\n",
      "CPU times: user 2 µs, sys: 2 µs, total: 4 µs\n",
      "Wall time: 8.34 µs\n"
     ]
    }
   ],
   "source": [
    "d.get_process_data()\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "listing_id                    int64\n",
       "local_price                 float64\n",
       "Unnamed: 0                    int64\n",
       "name                         object\n",
       "type                         object\n",
       "city                         object\n",
       "neighborhood                 object\n",
       "latitude                    float64\n",
       "longitude                   float64\n",
       "person_capacity               int64\n",
       "beds                          int64\n",
       "bedrooms                      int64\n",
       "bathrooms                   float64\n",
       "is_rebookable                  bool\n",
       "is_new_listing                 bool\n",
       "is_fully_refundable            bool\n",
       "is_host_highly_rated           bool\n",
       "is_business_travel_ready       bool\n",
       "pricing_weekly_factor       float64\n",
       "pricing_monthly_factor      float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "d.merge.dtypes"
   ]
  },
  {
   "source": [
    "### Methodes :\n",
    "##### separe des types\n",
    "##### methode delete duplicated\n",
    "##### enléve les NA\n",
    "##### drop useless futures columns\n",
    "##### deux types de quantitifs : catégories et les valeursa \n",
    "##### on pourra avoir les prix en focntion des arrondissements\n",
    "##### methode appelle toutes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "class FeatureRecipe:\n",
    "\n",
    "    def __init__(self,data:pd.DataFrame):\n",
    "        \"\"\" TODO : __init__ \"\"\"\n",
    "\n",
    "        self.data = data\n",
    "        self.continuous = None # float\n",
    "        self.categorical = None # Object\n",
    "        self.discrete = None # int\n",
    "        self.other = None\n",
    "        self.datetime = None\n",
    "\n",
    "    def separate_variable_types(self) -> None:\n",
    "        \"\"\"\" TODO : Diviser les types de variables dans un tableau \"\"\"\n",
    "        print(\"-- Diviser les types de variables dans un tableau --\")\n",
    "        self.continuous = [] # float\n",
    "        self.categorical = [] # Object\n",
    "        self.discrete = [] # int   \n",
    "        self.other = [] # other ( bool )\n",
    "        for col in self.data.columns :\n",
    "            if self.data[col].dtypes == int :\n",
    "                self.discrete.append(self.data[col])\n",
    "            elif self.data[col].dtypes == object :\n",
    "                self.categorical.append(self.data[col])\n",
    "            elif self.data[col].dtypes == float :\n",
    "                self.continuous.append(self.data[col])\n",
    "            else:\n",
    "                self.other.append(self.data[col])\n",
    "                          \n",
    "        print(\" The Amount of sepereted types:\\n Categories {} \\n Discrete {} \\n Continuous {} \\n Other {}\".format(len(self.categorical),len(self.discrete),len(self.continuous),len(self.other)))\n",
    "    \n",
    "    def drop_uselessf(self):\n",
    "        \"\"\" TODO : Supprimer les colonnes inutiles du dataset \"\"\"\n",
    "        print(\"-- Dropping uselese Columns--\")\n",
    "\n",
    "        if \"Unnamed : 0\" in self.data.columns :\n",
    "            self.data.drop(['Unnamed: 0'],axis='columns',inplace=True)\n",
    "\n",
    "        for col in self.data.columns :\n",
    "            if self.data[col].isna().sum() == len(self.data[col]) :\n",
    "                self.data.drop([col],axis='columns',inplace=True)\n",
    "\n",
    "        print(\"--Done Dropping--\")\n",
    "    \n",
    "    def deal_duplicate(self):\n",
    "        \"\"\" TODO : Supprimer les lignes dupliquées du dataset \"\"\"\n",
    "        \n",
    "        print(\"-- Duplicas Deletion commenced --\")\n",
    "        # Create an empty set \n",
    "        duplicateColumnNames = set() \n",
    "        # Iterate through all the columns of dataframe \n",
    "        for x in range(self.data.shape[1]): \n",
    "            # Take column at xth index. \n",
    "            col = self.data.iloc[:, x] \n",
    "            # Iterate through all the columns in DataFrame from (x + 1)th index to last index \n",
    "            for y in range(x + 1, self.data.shape[1]): \n",
    "                # Take column at yth index. \n",
    "                otherCol = self.data.iloc[:, y] \n",
    "                # Check if two columns at x & y index are equal or not, if equal then adding  to the set \n",
    "                if col.equals(otherCol): \n",
    "                    duplicateColumnNames.add(self.data.columns.values[y])\n",
    "        \n",
    "        #return list(duplicateColumnNames)\n",
    "        self.data = self.data.drop(columns = list(duplicateColumnNames),inplace=True)\n",
    "\n",
    "        print(\"-- Duplicas Deteted --\")\n",
    "\n",
    "    def drop_nanp(self, threshold: float):\n",
    "        \"\"\" \n",
    "            TODO : Supprimer un pourcentage de NA du dataset \n",
    "\n",
    "            Threshold is inserted from 0 to 100 float variable\n",
    "        \"\"\"\n",
    "        \n",
    "        dropped=[]\n",
    "        print(\"-- threshold est mis en Argument {}-- \".format(threshold))\n",
    "        for col in self.data.columns :\n",
    "            if (self.data[col].isna().sum()/self.data.shape[0]) >= threshold/100 : \n",
    "                dropped.append(col)\n",
    "        print(\"{} feature have more than {} NaN \".format(len(col), threshold))\n",
    "        print('\\n\\n - - - features - - -  \\n {}'.format(col))    \n",
    "        \n",
    "        self.data.drop(dropped,axis='columns',inplace=True)\n",
    "        print(\"-- Columns Dropped {}\".format(dropped))\n",
    "    \n",
    "    def deal_dtime(self):\n",
    "        \"\"\" TODO : Traiter les DateTime \"\"\"\n",
    "        pass\n",
    "\n",
    "    def prepare_data(self, threshold: float):\n",
    "        self.separate_variable_types()\n",
    "        self.drop_uselessf()\n",
    "        self.deal_duplicate()\n",
    "        self.drop_nanp(threshold)\n",
    "        self.deal_dtime()   \n",
    "        print(\"-- End of FeatureRecipe --\") "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = FeatureRecipe(d.merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-- Diviser les types de variables dans un tableau --\n The Amount of sepereted types:\n Categories 4 \n Discrete 5 \n Continuous 6 \n Other 5\n"
     ]
    }
   ],
   "source": [
    "fr.separate_variable_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-- Dropping uselese Columns--\n--Done Dropping--\n"
     ]
    }
   ],
   "source": [
    "fr.drop_uselessf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    \"\"\"\n",
    "    Feature Extractor class\n",
    "    \"\"\"    \n",
    "    def __init__(self, data: pd.DataFrame, flist: list):\n",
    "        \"\"\"\n",
    "            Input : pandas.DataFrame, feature list to drop\n",
    "            Output : X_train, X_test, y_train, y_test according to sklearn.model_selection.train_test_split\n",
    "        \"\"\"\n",
    "        self.df = data\n",
    "        self.flist = flist\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "\n",
    "    def extract(self):\n",
    "        print(\"-- X and y Values to be put while discarding the flist that we dont need--\")\n",
    "        for col in self.flist:\n",
    "            if col in self.df:\n",
    "                self.df.drop(col,axis=\"columns\",inplace=True)\n",
    "\n",
    "        print(\"-- Extraction Done --\")\n",
    "\n",
    "    def split(self,size:float,rand:int,y:str):\n",
    "        print(\"-- Using Split mehtode --\")\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.df.loc[:,self.df.columns!=y], self.df[y], test_size=size, random_state=rand)\n",
    "        print(\"-- Afficher la shape de vos données --\")\n",
    "\n",
    "    def get_process_data(self,size:float,rand:int,y:str):\n",
    "        self.extract()\n",
    "        self.split(size,rand,y)\n",
    "        print(\"-- Done processing Feature Extractor --\")\n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "\n"
   ]
  },
  {
   "source": [
    "  print(\"self.X_train.shape = {}, self.y_train.shape = {},\\n\\nself.X_test.shape = {}, self.y_test.shape = {}\".format(self.X_train.shape, self.y_train.shape,self.X_test.shape, self.y_test.shape))\n",
    "        \n",
    "        print(\"-- créer l'objet de régression et entrainer le sur notre ensemble d'entraînement --\")\n",
    "        regr= LinearRegression()\n",
    "        model= regr.fit(self.X_train,self.y_train)\n",
    "\n",
    "        print(\"-- On affiche le vecteur des coefficients pour interpréter rapidement le modèle --\")\n",
    "        \n",
    "        print(\"Model Coefficients so basicaly the X columns values for y values = {} , \\n Model Intercept Value = {} , \\n Score Result = {}\".format(model.coef_ , model.intercept_, regr.score(self.X_test,self.y_test)))\n",
    "\n",
    "        print(\"-- Test Train Split Done --\")\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = ['listing_id','city','neighborhood','latitude','longitude','is_rebookable','is_new_listing','is_fully_refundable','is_host_highly_rated','is_business_travel_ready','pricing_weekly_factor','pricing_monthly_factor','name','type']      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-- X and y Values to be put while discarding the flist that we dont need--\n-- Extraction Done --\n-- Using Split mehtode --\n-- Afficher la shape de vos données --\n-- Done processing Feature Extractor --\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureExtractor(d.merge,flist)\n",
    "X_train,X_test,y_train,y_test = fe.get_process_data(0.3,42,'local_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Unnamed: 0  person_capacity  beds  bedrooms  bathrooms\n",
       "728         746                4     2         1        1.0\n",
       "630         649                2     1         1        1.0\n",
       "394         415                6     4         3        1.5\n",
       "777         791                2     2         0        1.0\n",
       "598         617                2     1         1        1.0\n",
       "..          ...              ...   ...       ...        ...\n",
       "106         131                1     1         1        1.0\n",
       "270         291                6     3         2        1.0\n",
       "860         877                4     2         2        1.0\n",
       "435         456                5     1         1        1.0\n",
       "102         127                2     1         1        1.0\n",
       "\n",
       "[699 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>person_capacity</th>\n      <th>beds</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>728</th>\n      <td>746</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>630</th>\n      <td>649</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>394</th>\n      <td>415</td>\n      <td>6</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>777</th>\n      <td>791</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>598</th>\n      <td>617</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>131</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>270</th>\n      <td>291</td>\n      <td>6</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>877</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>435</th>\n      <td>456</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>127</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>699 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "728    298.366755\n",
       "630    109.421875\n",
       "394    330.000000\n",
       "777     40.067010\n",
       "598     70.434109\n",
       "          ...    \n",
       "106     40.234987\n",
       "270    382.621359\n",
       "860    115.000000\n",
       "435    104.789474\n",
       "102     92.281330\n",
       "Name: local_price, Length: 699, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBuilder:\n",
    "    \"\"\"\n",
    "        Class for train and print results of ml model \n",
    "    \"\"\"\n",
    "    def __init__(self, model_path: str = None, save: bool = None):\n",
    "        self.model_path=model_path\n",
    "        self.save=save\n",
    "        self.reg = LinearRegression()\n",
    "    def __repr__(self): # class courier python , affichage par default isntancié , methode __str__ \n",
    "        pass\n",
    "    def train(self,X,y):\n",
    "        self.fit(X,y)\n",
    "    def predict_test(self, X) -> np.ndarray:  # certain ligne of X_test or y_test \n",
    "        self.line_reg.fit(X,y)\n",
    "    def predict_from_dump(self, X) -> np.ndarray:\n",
    "        pass\n",
    "    def save_model(self, path:str): # joblib saving de predict_test of fit , et on faire le dump de joblib par la focntion de predict_from_dump\n",
    "        #with the format : 'model_{}_{}'.format(date)\n",
    "        result = pickle.dump(reg)\n",
    "        dump(result,\"model_{}.joblib\".format(DT.datetime.now()))\n",
    "        pass\n",
    "    def print_accuracy(self): # accuracy c'est le score \n",
    "        self.reg.predict(X_test)\n",
    "        self.reg.score(X_test,y_test)\n",
    "        pass\n",
    "    def load_model(self): # à partir de fichier joblib , je le mets en instance \n",
    "        #self.model en plsu de model baf... si j'ai pas chargé alors pas de modéle  , s'il y a alors charge\n",
    "        try:\n",
    "            #load model\n",
    "            pass\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataManager(d:DataHandler=None, fr: FeatureRecipe=None, fe:FeatureExtractor=None): # script model.py qui sort une model .joblib , alors dans model.py datamanager model builder et va sortir un fichier .joblib\n",
    "    \"\"\"\n",
    "        Fonction qui lie les 3 premières classes de la pipeline et qui return FeatureExtractor.split(0.1)\n",
    "    \"\"\"\n",
    "    pass\n",
    "#on appelera la fonction DataManager() de la facon suivante : \n",
    "X_train, X_test, y_train, y_test = DataManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ModelBuilder() \n",
    "m.train(X_train, y_train)\n",
    "m.print_accuracy()\n",
    "m.save_model(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}